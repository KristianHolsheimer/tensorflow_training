{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![LSTM](https://raw.githubusercontent.com/KristianHolsheimer/tensorflow_training/master/img/lstm.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Build an LSTM cell\n",
    "\n",
    "In the sequence of transformations (see fig. above), $x$ is the **input vector** at the current timestep. Notice that the memory cell **state vectors** $m$ and $c$ are updated at each timestep.\n",
    "\n",
    "### The Goal\n",
    "The goal of this exercise is to demystify LSTMs. In order to do this, you will construct your very own LSTM from the ground up.\n",
    "\n",
    "Let's get started!\n",
    "\n",
    "### Create some dummy data\n",
    "Let's suppose we have a data set $x$ of 7 features and 10 samples. Let's create some dummy data of the appropriate dimensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.9187018   0.33828914  0.31343234  0.59327048  0.01080375  0.6280915\n",
      "   0.39356742]]\n"
     ]
    }
   ],
   "source": [
    "n_features = 7\n",
    "\n",
    "# input data (one single data point)\n",
    "x = np.random.random([1, n_features])\n",
    "\n",
    "\n",
    "print x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Initialize the weights\n",
    "\n",
    "Randomly initialize all the weights using 5 hidden units:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_hidden = 5\n",
    "n_output = 3  # can be at most n_hidden\n",
    "\n",
    "\n",
    "# memory cell *output* (from previous step)\n",
    "h = np.random.random([1, n_hidden])\n",
    "\n",
    "# candidate memory cell *c-state* (from previous timestep)\n",
    "c = ...\n",
    "\n",
    "# memory cell *m-state* (from previous timestep)\n",
    "m = ...\n",
    "\n",
    "# input gate weights\n",
    "w_i = ...\n",
    "u_i = ...\n",
    "b_i = ...\n",
    "\n",
    "# candidate memory (c-state) weights\n",
    "w_c = ...\n",
    "u_c = ...\n",
    "b_c = ...\n",
    "\n",
    "# forget gate weights\n",
    "w_f = ...\n",
    "u_f = ...\n",
    "b_f = ...\n",
    "\n",
    "# output gate weights\n",
    "w_o = ...\n",
    "u_o = ...\n",
    "v_o = ...\n",
    "b_o = ...\n",
    "\n",
    "# output projection weights\n",
    "w_h = ...\n",
    "b_h = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load sol/ex_lstm_init_weights.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Implement the operations\n",
    "\n",
    "Here is the sequence of operations again:\n",
    "\n",
    "$ i\\ \\leftarrow\\ \\text{sigmoid}\\left(x\\cdot w_i + m\\cdot u_i + b_i\\right) $\n",
    "\n",
    "$ f\\ \\leftarrow\\ \\text{sigmoid}\\left(x\\cdot w_f + m\\cdot u_f + b_f\\right) $\n",
    "\n",
    "$ c\\ \\leftarrow\\ f\\odot c + i\\odot \\tanh\\left(x\\cdot w_c + m\\cdot u_c + b_c\\right) $\n",
    "\n",
    "$ o\\ \\leftarrow\\ \\text{sigmoid}\\left(x\\cdot w_o + m\\cdot u_o + c\\cdot v_o + b_o\\right) $\n",
    "\n",
    "$ m\\ \\leftarrow\\ o\\odot\\tanh\\left(c\\right) $\n",
    "\n",
    "$ h\\ \\leftarrow\\ \\tanh(m\\cdot w_h + b_h) $\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.special import expit as sigmoid\n",
    "\n",
    "# input gate\n",
    "i = sigmoid(np.dot(x, w_i) + b_i)\n",
    "\n",
    "# forget gate\n",
    "f = ...\n",
    "\n",
    "# candidate memory (c-state)\n",
    "c = ...\n",
    "\n",
    "# output gate\n",
    "o = ...\n",
    "\n",
    "# memory cell state (m-state)\n",
    "m = ...\n",
    "\n",
    "# output\n",
    "h = ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting sol/ex_lstm_operations.py\n"
     ]
    }
   ],
   "source": [
    "# %load sol/ex_lstm_operations.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it! You've just implemented your own LSTM cell. All that remains now is to organize our code a little bit.\n",
    "\n",
    "### c) Create your own LSTMCell class\n",
    "\n",
    "This exercise requires a slightly more advanced understanding of python, so feel free to peek at the solution below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class MyLSTMCell:\n",
    "    def __init__(self, n_hidden, n_output):\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_output = n_output\n",
    "        raise NotImplementedError('__init__')\n",
    "        \n",
    "    def _init_weights(self, n_features):\n",
    "        raise NotImplementedError('_init_weights')\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        raise NotImplementedError('__call__')\n",
    "        \n",
    "        return self.h\n",
    "\n",
    "\n",
    "lstm_cell = MyLSTMCell(5)\n",
    "lstm_cell(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load sol/ex_lstm_class_numpy.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) Translate to tensorflow\n",
    "\n",
    "Now define the `MyLSTMCell` class again, this time using tensorflow operations instead of numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def init_weights(shape):\n",
    "    return (...)\n",
    "\n",
    "\n",
    "def get_n_features(x):\n",
    "    return (...)\n",
    "\n",
    "\n",
    "sigmoid = tf.sigmoid\n",
    "tanh = (...)\n",
    "dot = (...)\n",
    "\n",
    "\n",
    "\n",
    "class MyLSTMCell:\n",
    "    \"same definition as the numpy version in the solution above\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load sol/ex_lstm_class_tensorflow.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I hope you're proud of yourself, you just created an LSTM cell very much like how it's defined in tensorflow. In fact, from now on, we're going to use the tensorflow's `LSTMCell`:\n",
    "```python\n",
    "from tensorflow.contrib.rnn import LSTMCell\n",
    "\n",
    "lstm_cell = LSTMCell(num_units=n_hidden, num_proj=n_output)\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "This class provides some additional functionality compared to our `MyLSTMCell` class.\n",
    "\n",
    "In the next notebook, we'll string together the LSTM cells in a simple model that will generate the next character in a sequence of characters, i.e. text."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
