{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'>Build the RNN</font>\n",
    "\n",
    "Now that we all of the necessary ingredients, it's time to put the pieces together.\n",
    "\n",
    "<font color='red'>**TODO:** Split up into smaller chunks and exercises.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients_impl.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, loss: 5.17539310455\n",
      "\n",
      "Seed: \"Hello\"\n",
      "Orig: Hello, world!\n",
      "Pred: tiiiiiiiiii\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\n",
      "\n",
      "Seed: \"Good \"\n",
      "Orig: Good bye now.\n",
      "Pred: ttiiiiiiiii\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\u001d",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch: 2, loss: 4.25486707687\n",
      "\n",
      "Seed: \"Good \"\n",
      "Orig: Good bye now.\n",
      "Pred: Hi;;iiiiiiii;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n",
      "\n",
      "Seed: \"Hi ag\"\n",
      "Orig: Hi again!\n",
      "Pred: Hiiiiiiiiiii;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch: 4, loss: 3.53653264046\n",
      "\n",
      "Seed: \"Hi ag\"\n",
      "Orig: Hi again!\n",
      "Pred: Hiiiiiiiii\n",
      "\n",
      "Seed: \"Hello\"\n",
      "Orig: Hello, world!\n",
      "Pred: HHiiiiiii\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch: 8, loss: 2.5659968853\n",
      "\n",
      "Seed: \"Hi ag\"\n",
      "Orig: Hi again!\n",
      "Pred: Ho         \n",
      "\n",
      "Seed: \"Good \"\n",
      "Orig: Good bye now.\n",
      "Pred: Hooo      \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch: 16, loss: 1.98946988583\n",
      "\n",
      "Seed: \"Hi ag\"\n",
      "Orig: Hi again!\n",
      "Pred: Higggaannn\n",
      "\n",
      "Seed: \"Hello\"\n",
      "Orig: Hello, world!\n",
      "Pred: Helggaannn\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch: 32, loss: 0.809058129787\n",
      "\n",
      "Seed: \"Hi ag\"\n",
      "Orig: Hi again!\n",
      "Pred: Hi again!\n",
      "\n",
      "Seed: \"Hello\"\n",
      "Orig: Hello, world!\n",
      "Pred: Hello,  roddd\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch: 64, loss: 0.0463435351849\n",
      "\n",
      "Seed: \"Hello\"\n",
      "Orig: Hello, world!\n",
      "Pred: Hello, world!\n",
      "\n",
      "Seed: \"Hi ag\"\n",
      "Orig: Hi again!\n",
      "Pred: Hi again!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch: 128, loss: 0.00533772306517\n",
      "\n",
      "Seed: \"Hi ag\"\n",
      "Orig: Hi again!\n",
      "Pred: Hi again!\n",
      "\n",
      "Seed: \"Hello\"\n",
      "Orig: Hello, world!\n",
      "Pred: Hello, world!\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWkAAAEOCAYAAABLiuasAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nu1ZoAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f77c5b5ff50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils import SentenceEncoder\n",
    "\n",
    "\n",
    "# static shapes\n",
    "n_hidden = 64\n",
    "n_chars = 129  # ascii + EOS = 128 + 1 = 129\n",
    "emb_dim = 13\n",
    "batch_size = 2\n",
    "warmup = 5\n",
    "\n",
    "# clear any previous computation graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# character embeddings\n",
    "emb = tf.Variable(tf.random_uniform([n_chars, emb_dim], dtype=tf.float32))\n",
    "\n",
    "# tf Graph input\n",
    "seq_enc = tf.placeholder(tf.int32, [batch_size, None])  # (batch_size, max_seqlen_within_batch)\n",
    "seq_mask = tf.placeholder(tf.bool, [batch_size, None])  # (batch_size, max_seqlen_within_batch)\n",
    "max_seqlen = tf.placeholder(tf.int32, [])\n",
    "\n",
    "# translate to dense vectors\n",
    "x = tf.nn.embedding_lookup(emb, seq_enc)  # (batch_size, max_seqlen_within_batch, emb_dim])\n",
    "x = tf.transpose(x, [1, 0, 2])            # tf.map_fn iterates over axis=0\n",
    "\n",
    "# rnn cell\n",
    "lstm_cell = tf.contrib.rnn.LSTMCell(n_hidden, num_proj=emb_dim, use_peepholes=True)\n",
    "\n",
    "# memory cell states\n",
    "c = tf.Variable(tf.random_uniform([1, n_hidden]))\n",
    "m = tf.Variable(tf.random_uniform([1, emb_dim]))\n",
    "c = tf.tile(c, [batch_size, 1])\n",
    "m = tf.tile(m, [batch_size, 1])\n",
    "\n",
    "\n",
    "def cond(i, h, c, m):\n",
    "    return i < max_seqlen\n",
    "\n",
    "def body(i, h, c, m):\n",
    "    prev_token = tf.cond(\n",
    "        i < warmup,\n",
    "        lambda: x[i],\n",
    "        lambda: tf.squeeze(h[-1])\n",
    "    )\n",
    "    \n",
    "    h_new, (c, m) = lstm_cell(prev_token, (c, m))\n",
    "    h_new = tf.expand_dims(h_new, 0)\n",
    "    \n",
    "    h = tf.concat([h, h_new], axis=0)\n",
    "    i += 1\n",
    "    return i, h, c, m\n",
    "\n",
    "\n",
    "shape_invariants = map(tf.TensorShape, (\n",
    "    [],                           # i.shape\n",
    "    [None, batch_size, emb_dim],  # h.shape\n",
    "    [batch_size, n_hidden],       # c.shape\n",
    "    [batch_size, emb_dim],        # m.shape\n",
    "))\n",
    "\n",
    "# run while loop\n",
    "h = tf.zeros([0, batch_size, emb_dim])\n",
    "h = tf.while_loop(cond, body, [0, h, c, m], shape_invariants)[1]\n",
    "\n",
    "# use Gaussian kernel for inter-embedding distances\n",
    "d = tf.norm(tf.map_fn(lambda e: h - e, emb), axis=-1)  # shape = (n_chars, max_seqlen_within_batch, batch_size)\n",
    "d = tf.transpose(d, [2, 1, 0])                         # shape = (batch_size, max_seqlen_within_batch, n_chars)\n",
    "\n",
    "# define loss function\n",
    "logits = -d ** 2                                         # shape = (batch_size, max_seqlen_within_batch, n_chars)\n",
    "labels = tf.one_hot(seq_enc, n_chars, dtype=tf.float32)  # shape = (batch_size, max_seqlen_within_batch, n_chars)\n",
    "loss = tf.nn.softmax_cross_entropy_with_logits(labels=labels, logits=logits)\n",
    "loss = tf.reduce_mean(tf.boolean_mask(loss, seq_mask))   # mask discards loss due to zero-padding\n",
    "\n",
    "# get the most likely predicted characters\n",
    "y_hat = tf.argmax(logits, axis=-1)  # shape = (batch_size, max_seqlen_within_batch)\n",
    "\n",
    "\n",
    "   \n",
    "def fit_model(sents, learning_rate=1e-2, n_epochs=128):\n",
    "    \"\"\"\n",
    "    This function contains the usual boiler plate required to feed the\n",
    "    input data and to print some training diagnostics.\n",
    "    \n",
    "    Params\n",
    "    ------\n",
    "    sents : sequence of strings\n",
    "        The text on which to train / predict.\n",
    "        \n",
    "    learning_rate : float\n",
    "        AdamOptimizer learning rate.\n",
    "        \n",
    "    n_epochs : int\n",
    "        Numer of epochs to use at training time.\n",
    "    \n",
    "    \"\"\"\n",
    "    # optimizer\n",
    "    train = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "    encoder = SentenceEncoder(sents, batch_size=batch_size)\n",
    "\n",
    "    with tf.Session() as s:\n",
    "        s.run(tf.global_variables_initializer())\n",
    "        learning_curve = {}\n",
    "        for epoch in xrange(1, n_epochs + 1):\n",
    "            for seq_enc_, seqlen_, seq_mask_, max_seqlen_ in encoder:\n",
    "                _, loss_ = s.run(\n",
    "                    (train, loss),\n",
    "                    feed_dict={\n",
    "                        seq_enc: seq_enc_,\n",
    "                        seq_mask: seq_mask_,\n",
    "                        max_seqlen: max_seqlen_})\n",
    "\n",
    "            if np.log2(epoch).is_integer():\n",
    "                print \"Epoch: {}, loss: {}\\n\".format(epoch, loss_)\n",
    "                learning_curve[epoch] = loss_\n",
    "\n",
    "                # create prediction data\n",
    "                seq_enc_ = list(encoder)[0][0][:2]  # get just two sentences\n",
    "                seqlen_ = 100\n",
    "                seq_mask_ = np.zeros([batch_size, seqlen_], dtype=np.bool)\n",
    "                seed = np.zeros([batch_size, seqlen_], dtype=np.int32)\n",
    "                seed[:,:warmup] = seq_enc_[:,:warmup]\n",
    "                y_hat_ = s.run(\n",
    "                    y_hat,\n",
    "                    feed_dict={\n",
    "                        seq_enc: seed,\n",
    "                        seq_mask: seq_mask_,\n",
    "                        max_seqlen: seqlen_})\n",
    "\n",
    "                for s1, s2 in zip(encoder.decode(seq_enc_), encoder.decode(y_hat_)):\n",
    "                    print \"Seed: \\\"{}\\\"\".format(s1[:warmup])\n",
    "                    print \"Orig: {}\".format(s1)\n",
    "                    print \"Pred: {}\\n\".format(s2)\n",
    "\n",
    "                print \"-\" * 80\n",
    "\n",
    "    learning_curve = pd.Series(learning_curve)\n",
    "    learning_curve.plot(logx=True, style='o-', title='KL divergence')\n",
    "\n",
    "\n",
    "# some simple input sentences\n",
    "sents = [\"Hello, world!\", \"Hi again!\", \"Good bye now.\"]\n",
    "\n",
    "fit_model(sents)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
